

import streamlit as st 
import os
from dotenv import load_dotenv
from google import genai

st.title("ðŸ‘Ÿ Sneakers AI DEMO")

SYSTEM_PROMPT = (
    "VocÃª Ã© a Sneaker AI, um assistente virtual especializado em tÃªnis e cultura sneaker. "
    "Fale sempre com entusiasmo, paixÃ£o e conhecimento profundo sobre o universo dos tÃªnis. "
    "Use humor e energia, e trate o usuÃ¡rio como se fosse um grande amigo fÃ£ de tÃªnis."
)

if 'messages' not in st.session_state:
    st.session_state.messages = []
    
for message in st.session_state["messages"]:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        
        
# ---- ConexÃ£o com a API do Gemini -----

load_dotenv()

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not GEMINI_API_KEY:
    st.error("Chave GEMINI_API_KEY nÃ£o encontrada.")
    st.stop()
    
try:
    client = genai.Client(api_key=GEMINI_API_KEY)
except Exception as e:
    st.error(f"Erro ao conectar com a API do Gemini: {e}")
    st.stop()
    
# ------- FunÃ§Ã£o de ComunicaÃ§Ã£o com IA -------

def get_gemini_response(prompt):
    history = [
        {"role":"user", "parts":[{"text":SYSTEM_PROMPT}]}
    ]
    for message in st.session_state["messages"]:
        role = "model" if message["role"] == "assistant" else "user"
        history.append({"role": role, "parts": [{"text": message ["content"]}]})
    chat = client.chats.create(model="gemini-2.5-flash", history=history)
    response = chat.send_message(prompt)
    return response.text

#----- LÃ³gica de Input/Output --------

if prompt := st.chat_input("Fale com a Sneakers AI! ðŸ‘Ÿ"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    with st.spinner("ðŸ’­ Sneaker AI estÃ¡ pensando....."):
        response_text = get_gemini_response(prompt)
    st.session_state.messages.append({"role": "assistant", "content": response_text})
    with st.chat_message("assistant"):
        st.markdown(response_text)
